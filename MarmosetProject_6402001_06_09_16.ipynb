{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prawees/marmoset_project/blob/main/MarmosetProject_6402001_06_09_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hbq_HOgeFxQ"
      },
      "outputs": [],
      "source": [
        "!wget https://zenodo.org/records/5849371/files/marmoset-dlc-2021-05-07.zip -O marmoset_data.zip\n",
        "#Download dataset and name it marmoset_data.zip\n",
        "!unzip marmoset_data.zip -d ./marmoset\n",
        "#Unzip file\n",
        "!pip install ultralytics deeplabcut2yolo\n",
        "#Install ultralytics and deeplabcut2yolo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9StKRtl5etPc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import deeplabcut2yolo\n",
        "\n",
        "json = \"./marmoset/marmoset-dlc-2021-05-07/training-datasets/iteration-0/UnaugmentedDataSet_marmosetMay7/dlc_shuffle1_train.json\"\n",
        "#path to the DeepLabCut annotation file (.json format)\n",
        "csv = \"./marmoset/marmoset-dlc-2021-05-07/training-datasets/iteration-0/UnaugmentedDataSet_marmosetMay7/CollectedData_dlc.csv\"\n",
        "#path to the .csv file\n",
        "save = \"./marmoset/marmoset-dlc-2021-05-07/labeled-data/\"\n",
        "#the directory where the converted YOLO-compatible data will be saved\n",
        "\n",
        "deeplabcut2yolo.convert(json, csv, save, datapoint_classes=[0, 1], n_keypoint_per_datapoint=30, precision=6)\n",
        "#Use fucntion deeplabcut2yolo.convert() to convert deeplabcut data into YOLO-compatible data\n",
        "#datapoint_classes = classes labels for the datapoints (in this case there are two monkeys to detect)\n",
        "#n_keypoint_per_datapoint = number of keypoints per datapoint\n",
        "#precision = decimal precision for the converted annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-l1Cmmhe0c8"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "data = {\n",
        "    \"train\": \"/content/marmoset/marmoset-dlc-2021-05-07/labeled-data/reachingvideo1\",\n",
        "    #path to the data that will use to train the model\n",
        "    \"val\": \"/content/marmoset/marmoset-dlc-2021-05-07/labeled-data/refinement1\",\n",
        "    #path to the data that will use to validate the model\n",
        "    \"kpt_shape\": [15, 3],\n",
        "    #keypoint shape: in this case there are 15 keypoints per class  and each keypoints hold 3 values (x, y, confidence score)\n",
        "    \"flip_idx\":  [0, 3, 2, 1, 6, 7, 4, 5, 9, 8, 11, 10, 12, 13, 14],\n",
        "    #flip index: defines which keypoints should be swapped when the image is horizontally flipped (mirrored)\n",
        "    \"nc\": 2,\n",
        "    #number of classes\n",
        "    \"names\" : [\"B\", \"W\"]\n",
        "    #name of classes\n",
        "    }\n",
        "\n",
        "output= \"/content/output.yaml\"\n",
        "#the directory where the yml data will be saved\n",
        "\n",
        "with open(output, \"w\") as file:\n",
        "    yaml.dump(data, file, default_flow_style=None, sort_keys=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd1kZc9Ie6cP",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "modelyolo = YOLO(\"yolov8n-pose.pt\")\n",
        "\n",
        "modelyolo.train(data=\"output.yaml\", epochs=20)\n",
        "#train YOLO model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://zenodo.org/records/8437121/files/marmoset-dlc-2021-05-07.zip -O marmoset_test.zip\n",
        "!unzip marmoset_test.zip -d ./marmoset_test"
      ],
      "metadata": {
        "id": "VQqgCBu_ddJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import SAM\n",
        "\n",
        "# Load a model\n",
        "modelsam = SAM(\"sam_b.pt\")"
      ],
      "metadata": {
        "id": "DcDcuwFuYCp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define input and output directories\n",
        "input_dir = \"./marmoset_test/marmoset-dlc-2021-05-07/labeled-data/reachingvideo1\"\n",
        "output_dir = \"./marmoset_test/marmoset-dlc-2021-05-07/labeled-data/output\"\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "if os.path.exists(output_dir) == False:\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.lower().endswith(('.png')):\n",
        "        # Path to the image\n",
        "        image_path = os.path.join(input_dir, filename)\n",
        "\n",
        "        # Run YOLO model\n",
        "        model_output = modelyolo(image_path)\n",
        "        boxes = model_output[0].boxes.xyxy\n",
        "\n",
        "        # Check bounding boxes\n",
        "        if len(boxes) == 0:\n",
        "            print(f\"No {filename}\")\n",
        "            continue\n",
        "\n",
        "        # Convert bounding boxes to list format suitable for SAM\n",
        "        bboxes_list = boxes[0].cpu().numpy().tolist()  # Convert to numpy array and then to list\n",
        "\n",
        "        # Run SAM model with bounding boxes\n",
        "        resultsam = modelsam(image_path, bboxes=bboxes_list)\n",
        "\n",
        "        # Save the annotated image\n",
        "        result = resultsam[0]\n",
        "        output_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_a.png\")\n",
        "        result.save(output_path)\n",
        "        print(f\"{output_path} saved. \\n\")"
      ],
      "metadata": {
        "id": "jOaMTavdxGgZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}